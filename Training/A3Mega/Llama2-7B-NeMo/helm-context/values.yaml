# Copyright 2024 Google LLC
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

targetPlatform: "gke"
#queue: "multislice-queue"

volumes:
  # The VM host path for SSDs is assumed at /mnt/stateful_partition/kube-ephemeral-ssd
  ssdMountPath: "/ssd"

gcsDownload: # downloads or synchronizes contents of a GCS bucket folder on initialization
  source: "gs://nemo-megatron-demo/training-data/tokenized/sentencepiece-llama2/wikipedia" 
  target: "/ssd/.cache/"

workload:
  # This should be the image built and pushed to the registry (EDIT THIS)
  image: "/address/to/image/built/and/uploaded/<image_name>:<image_tag>"

  torchDistributedTarget: "/opt/NeMo/examples/nlp/language_modeling/megatron_gpt_pretraining.py"

  # It will be mounted to /nfs on container startup using GCS fuse (EDIT THIS)
  gcsBucketForDataCataPath: <bucket_name>

  # (EDIT THIS TO MATCH CHOSEN CONFIGURATION, can be one of {16,128,256,512,1024})
  gpus: 16
  arguments:
  # These argument name will be prefixed with '+' (see https://hydra.cc/docs/advanced/override_grammar/basic/)
  - name: "exp_manager.explicit_log_dir"
    value: "/nemo-experiments/results" 
  - name: "exp_manager.exp_dir"
    value: "/nemo-experiments/"
  - name: "model.data.index_mapping_dir"
    value: "/gcs/index_mapping_dir"
  - name: "model.data.data_prefix"
    value: "[1.0,/ssd/.cache/wikipedia-tokenized-for-llama2]"    
  - name: "model.tokenizer.model"
    value: "/ssd/.cache/llama-2-7b-megatron-checkpoint/tokenizer.model"     

  # If not 'null', launches a Tensorboard server on first node. By design, the job will then not exit on first node.
  # This is primarly intended for debugging purposes, when a shared file-system or external Tensorboard is unavailable.  
  embeddedTensorboardTarget: null

network:
  stack: "tcpxo" # one of {"tcp", "tcpx", "tcpxo"}

  daemonVersion: "us-docker.pkg.dev/gce-ai-infra/gpudirect-tcpxo/tcpgpudmarxd-dev:v1.0.8"
  pluginVersion: "us-docker.pkg.dev/gce-ai-infra/gpudirect-tcpxo/nccl-plugin-gpudirecttcpx-dev:v1.0.1"
    

  ncclSettings:
  - name: TRAINING_FILENAME
    value: "mixtral-8x7b-nvidia-configs.yaml"
  - name: IMAGE_VERSION
    value: "24.05"
    
  - name: NCCL_DEBUG
    value: "VERSION"
  - name: NCCL_ALGO
    value: "Ring,Tree"

  # The following NCCL settings are recommended for TCPxo only (but tunable):
  - name: NCCL_MIN_NCHANNELS
    value: "4"

